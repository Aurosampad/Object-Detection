{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "fmCt0-ceD9jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "-twqUY0rENcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=f\"/content/OJ_input.mp4\""
      ],
      "metadata": {
        "id": "FCZwgXHdEZ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics==8.0.10\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "i3xK5rUBFMDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install loguru lap thop # Remove the -q flag to see installation output\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox._version:\", yolox.__version__)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DmF4Xorf7dlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "  track_thresh: float = 0.25\n",
        "  track_buffer: int = 30\n",
        "  match_thresh: float = 0.8\n",
        "  aspect_ratio_thresh: float = 3.0\n",
        "  min_box_area: float = 1.0\n",
        "  mot20: bool = False"
      ],
      "metadata": {
        "id": "Jj4DjkOvHEZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "id": "MO2gEpA2IKUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"yolov8x.pt\""
      ],
      "metadata": {
        "id": "EkQmeLtnIc7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "id": "H1i-oewpJfv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model=yolov8x.pt conf=0.25 source={video_path}"
      ],
      "metadata": {
        "id": "txytiNC5JlO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES_DICT = model.model.names"
      ],
      "metadata": {
        "id": "UN0mNPD1NW4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.geometry.dataclasses import Point\n",
        "\n",
        "LINE_START = Point(50,1500)\n",
        "LINE_END = Point(3840-50,1500)"
      ],
      "metadata": {
        "id": "Jb17NH0eO2SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_PATH=f\"{HOME}/content/object_detection.mp4\""
      ],
      "metadata": {
        "id": "kM7pqd0tPS43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.video.dataclasses import VideoInfo\n",
        "\n",
        "VideoInfo.from_video_path(video_path)"
      ],
      "metadata": {
        "id": "ro6a7CALPu5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "UJewBSZ1cJRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.video.source import get_video_frames_generator\n",
        "\n",
        "# importing utility for displaying the picked frame in notebook\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
        "from supervision.geometry.dataclasses import Point\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "# frame generator used to read frames one after another\n",
        "generator = get_video_frames_generator(video_path)\n",
        "\n",
        "line_counter = LineCounter(start=Point(50, 1500), end=Point(3840-50, 1500))\n",
        "\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# line annotator for displaying the line\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness = 4, text_scale=2)\n",
        "\n",
        "video_info = VideoInfo.from_video_path(video_path)\n",
        "\n",
        "with VideoSink(TARGET_PATH, video_info) as sink:\n",
        "  for frame in tqdm(generator, total=video_info.total_frames):\n",
        "\n",
        "    # picking a frame from the generator\n",
        "    # iterator = iter(generator)\n",
        "\n",
        "    # # picking the next frame\n",
        "    # frame = next(iterator)\n",
        "\n",
        "    results = model(frame)[0]\n",
        "\n",
        "    detections = Detections(\n",
        "        xyxy = results.boxes.xyxy.cpu().numpy(),\n",
        "        confidence = results.boxes.conf.cpu().numpy(),\n",
        "        class_id = results.boxes.cls.cpu().numpy().astype(int)\n",
        "    )\n",
        "\n",
        "    tracks = byte_tracker.update(\n",
        "        output_results = detections2boxes(detections=detections),\n",
        "        img_info = frame.shape,\n",
        "        img_size = frame.shape\n",
        "    )\n",
        "    tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "    detections.tracker_id = np.array(tracker_id)\n",
        "\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "        for _, confidence, class_id, tracker_id in detections\n",
        "    ]\n",
        "\n",
        "    line_counter.update(detections=detections)\n",
        "\n",
        "    frame = box_annotator.annotate(frame=frame, detections=detections,labels=labels)\n",
        "    line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "\n",
        "    sink.write_frame(frame)"
      ],
      "metadata": {
        "id": "nRTMoj7xliyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}